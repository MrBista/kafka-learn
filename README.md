# Kafka Core Concepts - Lengkap dan Mudah Dipahami

## 1. TOPIC (Topik) ğŸ“

**Analogi Sederhana**: Topic seperti **folder email** atau **channel WhatsApp group**

```
Topic: "user-events"
â”œâ”€â”€ User A registered
â”œâ”€â”€ User B logged in  
â”œâ”€â”€ User C updated profile
â””â”€â”€ User D logged out
```

**Karakteristik Topic:**
- Nama topic harus unik dalam cluster
- Bisa menyimpan berbagai jenis message dengan struktur yang sama
- Immutable (sekali ditulis, tidak bisa diubah)
- Append-only (data baru selalu ditambah di akhir)

**Contoh Naming Convention:**
```
e-commerce-order-created
payment-success
user-registration
inventory-updated
notification-email
```

---

## 2. PARTITION (Partisi) ğŸ—‚ï¸

**Analogi Sederhana**: Partition seperti **rak buku yang berbeda** dalam satu perpustakaan

```
Topic: "orders"
â”‚
â”œâ”€â”€ Partition 0: [Order1] [Order4] [Order7] ...
â”œâ”€â”€ Partition 1: [Order2] [Order5] [Order8] ...  
â””â”€â”€ Partition 2: [Order3] [Order6] [Order9] ...
```

**Mengapa Butuh Partition?**

1. **Parallelism**: Multiple consumer bisa baca secara bersamaan
2. **Scalability**: Data terdistribusi di multiple server
3. **Ordering**: Dalam satu partition, urutan message dijaga

**Contoh Partitioning Strategy:**
```
// Berdasarkan User ID
user_id: 12345 â†’ hash(12345) % 3 = Partition 1
user_id: 67890 â†’ hash(67890) % 3 = Partition 2

// Semua order dari user yang sama akan ke partition yang sama
// Sehingga urutan order per user tetap terjaga
```

---

## 3. PRODUCER (Pengirim Pesan) ğŸ“¤

**Analogi Sederhana**: Producer seperti **pengirim surat**

**Tanggung Jawab Producer:**
- Memilih topic tujuan
- Menentukan key dan value message
- Memilih partition (atau biarkan Kafka yang tentukan)
- Handle retry jika gagal send

**Contoh Flow Producer:**
```
1. Application Event Occurs
   â”œâ”€â”€ User registers
   â””â”€â”€ Order created
   
2. Create Message
   â”œâ”€â”€ Key: user-123
   â”œâ”€â”€ Value: {"userId": 123, "email": "user@example.com"}
   â””â”€â”€ Headers: {"source": "user-service"}
   
3. Send to Kafka
   â”œâ”€â”€ Choose Topic: "user-events"
   â”œâ”€â”€ Kafka determines Partition based on key
   â””â”€â”€ Message stored with offset number
```

**Producer Configuration Penting:**
- `acks`: Level acknowledgment (0, 1, all)
- `retries`: Berapa kali retry jika gagal
- `batch.size`: Ukuran batch untuk efficiency
- `linger.ms`: Waktu tunggu sebelum send batch

---

## 4. CONSUMER (Penerima Pesan) ğŸ“¥

**Analogi Sederhana**: Consumer seperti **mailman yang ngambil surat**

**Tanggung Jawab Consumer:**
- Subscribe ke satu atau lebih topic
- Baca message secara sequential per partition
- Track offset (posisi terakhir yang sudah dibaca)
- Process message dan commit offset

**Contoh Flow Consumer:**
```
1. Subscribe to Topic
   â””â”€â”€ Topic: "user-events"
   
2. Poll for Messages
   â”œâ”€â”€ Get batch of messages
   â”œâ”€â”€ Current offset: 1500
   â””â”€â”€ Read messages 1500-1520
   
3. Process Messages
   â”œâ”€â”€ Send welcome email
   â”œâ”€â”€ Update user analytics
   â””â”€â”€ Log activity
   
4. Commit Offset
   â””â”€â”€ Mark messages as processed (offset: 1520)
```

---

## 5. CONSUMER GROUP ğŸ‘¥

**Analogi Sederhana**: Consumer Group seperti **tim kantor pos**

```
Topic "orders" dengan 3 Partition:
â”‚
Consumer Group "order-processors":
â”œâ”€â”€ Consumer A â†’ reads from Partition 0
â”œâ”€â”€ Consumer B â†’ reads from Partition 1  
â””â”€â”€ Consumer C â†’ reads from Partition 2

Jika Consumer B mati:
â”œâ”€â”€ Consumer A â†’ reads from Partition 0 + 1
â””â”€â”€ Consumer C â†’ reads from Partition 2
```

**Keuntungan Consumer Group:**
- **Load Balancing**: Partition didistribusi ke multiple consumer
- **Fault Tolerance**: Jika satu consumer mati, yang lain ambil alih
- **Scalability**: Tambah consumer untuk handle load lebih besar

**Aturan Consumer Group:**
- Satu partition hanya bisa dibaca oleh satu consumer dalam group
- Jika consumer > partition, ada consumer yang idle
- Jika partition > consumer, satu consumer handle multiple partition

---

## 6. OFFSET (Penanda Posisi) ğŸ”¢

**Analogi Sederhana**: Offset seperti **bookmark di buku**

```
Partition 0:
[Msg0] [Msg1] [Msg2] [Msg3] [Msg4] [Msg5] ...
   â†‘              â†‘                    â†‘
Offset 0       Offset 2            Offset 5
             (Last Read)        (Latest Message)
```

**Jenis-jenis Offset:**
- **Current Offset**: Posisi terakhir yang sudah di-commit
- **Latest Offset**: Message terbaru di partition
- **Earliest Offset**: Message tertua yang masih tersimpan

**Auto Commit vs Manual Commit:**
```
// Auto Commit (Default)
- Offset otomatis di-commit setiap 5 detik
- Risiko: Message bisa hilang jika crash sebelum commit

// Manual Commit  
- Developer kontrol kapan commit offset
- Lebih aman tapi butuh handling error lebih complex
```

---

## 7. BROKER (Server Kafka) ğŸ–¥ï¸

**Analogi Sederhana**: Broker seperti **kantor pos pusat**

**Tanggung Jawab Broker:**
- Menyimpan message dari producer
- Melayani request dari consumer  
- Manage partition dan replication
- Coordinate dengan broker lain

**Kafka Cluster:**
```
Cluster "my-kafka"
â”œâ”€â”€ Broker 1 (Leader untuk Partition 0)
â”œâ”€â”€ Broker 2 (Leader untuk Partition 1)
â””â”€â”€ Broker 3 (Leader untuk Partition 2)

Setiap partition punya:
- 1 Leader (handle read/write)
- N Follower (backup data)
```

---

## 8. REPLICATION (Replikasi) ğŸ”„

**Analogi Sederhana**: Replication seperti **fotokopi dokumen penting**

```
Topic "payments" dengan Replication Factor = 3:

Partition 0:
â”œâ”€â”€ Broker 1 (Leader) âœ…
â”œâ”€â”€ Broker 2 (Follower) âœ… 
â””â”€â”€ Broker 3 (Follower) âœ…

Jika Broker 1 mati:
â”œâ”€â”€ Broker 2 (New Leader) âœ…
â””â”€â”€ Broker 3 (Follower) âœ…
```

**In-Sync Replicas (ISR):**
- Replica yang up-to-date dengan leader
- Hanya ISR yang bisa jadi leader baru
- Memastikan data consistency

---

## 9. ZOOKEEPER ğŸ˜

**Analogi Sederhana**: Zookeeper seperti **buku telepon dan koordinator**

**Fungsi Zookeeper:**
- Menyimpan metadata cluster (topic, partition, broker info)
- Leader election untuk partition
- Configuration management
- Service discovery

**Note**: Kafka versi terbaru (2.8+) mulai bisa jalan tanpa Zookeeper dengan KRaft mode.

---

## 10. MESSAGE STRUCTURE ğŸ“¬

**Struktur Message Kafka:**
```
Message:
â”œâ”€â”€ Key (Optional): "user-123"
â”œâ”€â”€ Value: {"userId": 123, "action": "login"}  
â”œâ”€â”€ Headers: {"source": "auth-service", "version": "v1"}
â”œâ”€â”€ Timestamp: 2024-01-15T10:30:00Z
â””â”€â”€ Offset: 1234
```

**Key vs Value:**
- **Key**: Menentukan partitioning, bisa null
- **Value**: Data utama message, bisa null  
- **Headers**: Metadata tambahan untuk routing/filtering

---

## FLOW LENGKAP: Dari Producer ke Consumer

```
1. PRODUCER SIDE:
   App Event â†’ Create Message â†’ Choose Topic â†’ Kafka determines Partition â†’ Store in Log
   
2. KAFKA SIDE:
   Message stored â†’ Replicate to followers â†’ Update ISR â†’ Send ack to producer
   
3. CONSUMER SIDE:
   Poll messages â†’ Process batch â†’ Commit offset â†’ Continue polling
```

---

## PRACTICAL EXAMPLE: E-Commerce Order System

```
Scenario: User membuat order baru

1. ORDER SERVICE (Producer):
   Topic: "orders"
   Key: "user-123" (untuk partitioning)
   Value: {
     "orderId": "ord-456",
     "userId": "user-123", 
     "items": [...],
     "total": 150000
   }

2. KAFKA:
   - Message masuk ke partition berdasarkan hash(user-123)
   - Disimpan dengan offset baru
   - Replicate ke broker lain

3. CONSUMERS:
   â”œâ”€â”€ INVENTORY SERVICE â†’ Update stock
   â”œâ”€â”€ PAYMENT SERVICE â†’ Process payment
   â”œâ”€â”€ EMAIL SERVICE â†’ Send confirmation
   â””â”€â”€ ANALYTICS SERVICE â†’ Update metrics
```

Setiap service bisa process secara independent dan pada kecepatan berbeda!

---

## KEY TAKEAWAYS ğŸ¯

1. **Topic** = Channel untuk kategori message
2. **Partition** = Pembagian topic untuk parallelism dan scalability  
3. **Producer** = Pengirim message ke topic
4. **Consumer** = Penerima message dari topic
5. **Consumer Group** = Sekumpulan consumer yang bekerja sama
6. **Offset** = Bookmark posisi pembacaan message
7. **Broker** = Server yang menyimpan dan melayani data
8. **Replication** = Backup data untuk high availability

**Ingat**: Kafka adalah tentang **streaming data** secara **real-time**, **scalable**, dan **fault-tolerant**!